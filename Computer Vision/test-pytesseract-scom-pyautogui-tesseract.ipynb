{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytesseract --help-oem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import imutils\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import argparse\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_predictions(scores, geometry):\n",
    "    (numRows, numCols) = scores.shape[2:4]\n",
    "    rects= []\n",
    "    confidences = []\n",
    "    \n",
    "    for y in range(0, numRows):\n",
    "        scoresData = scores[0, 0, y]\n",
    "        xData0 = geometry[0, 0, y]\n",
    "        xData1 = geometry[0, 1, y]\n",
    "        xData2 = geometry[0, 2, y]\n",
    "        xData3 = geometry[0, 3, y]\n",
    "        anglesData = geometry[0, 4, y]\n",
    "        \n",
    "        for x in range(0, numCols):\n",
    "            if scoresData[x] < args[\"min_confidence\"]:\n",
    "                continue\n",
    " \n",
    "            (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
    " \n",
    "            angle = anglesData[x]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    " \n",
    "            h = xData0[x] + xData2[x]\n",
    "            w = xData1[x] + xData3[x]\n",
    " \n",
    "            endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "            endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "            startX = int(endX - w)\n",
    "            startY = int(endY - h)\n",
    " \n",
    "            rects.append((startX, startY, endX, endY))\n",
    "            confidences.append(scoresData[x])\n",
    " \n",
    "    return (rects, confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install easydict\n",
    "\n",
    "import  easydict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the argument parser and parse the arguments\n",
    "\n",
    "parser = easydict.EasyDict()\n",
    "parser.add_argument(\"--image\", type=str, help=\"path to input image\")\n",
    "parser.add_argument(\"--east\", type=str, help=\"path to input EAST text detector\")\n",
    "parser.add_argument(\"--min\", type=float, default=0.5, help=\"minimum probability required to inspect a region\")\n",
    "parser.add_argument(\"--width\", type=int, default=320, help=\"nearest multiple of 32 for resized width\")\n",
    "parser.add_argument(\"--height\", type=int, default=320, help=\"nearest multiple of 32 for resized height\")\n",
    "parser.add_argument(\"--padding\", type=float, default=0.0, help=\"amount of padding to add to each border of ROI\")\n",
    "\n",
    "# parser.add_argument(\"path to input image\")\n",
    "# parser.add_argument(\"path to input EAST text detector\")\n",
    "# parser.add_argument(\"minimum probability required to inspect a region\")\n",
    "# parser.add_argument(\"nearest multiple of 32 for resized width\")\n",
    "# parser.add_argument(\"nearest multiple of 32 for resized height\")\n",
    "# parser.add_argument(\"amount of padding to add to each border of ROI\")\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the input image and grab the image dimensions\n",
    "image = cv2.imread(args[\"image\"])\n",
    "orig = image.copy()\n",
    "(origH, origW) = image.shape[:2]\n",
    "\n",
    "# set the new width and height and then determine the ratio in change\n",
    "# for both the width and height\n",
    "(newW, newH) = (args[\"width\"], args[\"height\"])\n",
    "rW = origW / float(newW)\n",
    "rH = origH / float(newH)\n",
    "\n",
    "# resize the image and grab the new image dimensions\n",
    "image = cv2.resize(image, (newW, newH))\n",
    "(H, W) = image.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layerNames = [\n",
    "    \"feature_fusion/Conv_7/Sigmoid\",\n",
    "    \"feature_fusion/concat_3\"]\n",
    "\n",
    "# load the pre-trained EAST text detector\n",
    "print(\"[INFO] loading EAST text detector...\")\n",
    "net = cv2.dnn.readNet(args[\"east\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a blob from the image and then perform a forward pass of\n",
    "# the model to obtain the two output layer sets\n",
    "blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),\n",
    "    (123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "net.setInput(blob)\n",
    "(scores, geometry) = net.forward(layerNames)\n",
    "\n",
    "# decode the predictions, then  apply non-maxima suppression to\n",
    "# suppress weak, overlapping bounding boxes\n",
    "(rects, confidences) = decode_predictions(scores, geometry)\n",
    "boxes = non_max_suppression(np.array(rects), probs=confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the list of results\n",
    "results = []\n",
    "\n",
    "# loop over the bounding boxes\n",
    "for (startX, startY, endX, endY) in boxes:\n",
    "\t# scale the bounding box coordinates based on the respective\n",
    "\t# ratios\n",
    "\tstartX = int(startX * rW)\n",
    "\tstartY = int(startY * rH)\n",
    "\tendX = int(endX * rW)\n",
    "\tendY = int(endY * rH)\n",
    "\n",
    "\t# in order to obtain a better OCR of the text we can potentially\n",
    "\t# apply a bit of padding surrounding the bounding box -- here we\n",
    "\t# are computing the deltas in both the x and y directions\n",
    "\tdX = int((endX - startX) * args[\"padding\"])\n",
    "\tdY = int((endY - startY) * args[\"padding\"])\n",
    "\n",
    "\t# apply padding to each side of the bounding box, respectively\n",
    "\tstartX = max(0, startX - dX)\n",
    "\tstartY = max(0, startY - dY)\n",
    "\tendX = min(origW, endX + (dX * 2))\n",
    "\tendY = min(origH, endY + (dY * 2))\n",
    "\n",
    "\t# extract the actual padded ROI\n",
    "\troi = orig[startY:endY, startX:endX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tconfig = (\"-l eng --oem 1 --psm 7\")\n",
    "\ttext = pytesseract.image_to_string(roi, config=config)\n",
    " \n",
    "\t# add the bounding box coordinates and OCR'd text to the list\n",
    "\t# of results\n",
    "\tresults.append(((startX, startY, endX, endY), text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the results bounding box coordinates from top to bottom\n",
    "results = sorted(results, key=lambda r:r[0][1])\n",
    "\n",
    "# loop over the results\n",
    "for ((startX, startY, endX, endY), text) in results:\n",
    "\t# display the text OCR'd by Tesseract\n",
    "\tprint(\"OCR TEXT\")\n",
    "\tprint(\"========\")\n",
    "\tprint(\"{}\\n\".format(text))\n",
    "\n",
    "\t# strip out non-ASCII text so we can draw the text on the image\n",
    "\t# using OpenCV, then draw the text and a bounding box surrounding\n",
    "\t# the text region of the input image\n",
    "\ttext = \"\".join([c if ord(c) < 128 else \"\" for c in text]).strip()\n",
    "\toutput = orig.copy()\n",
    "\tcv2.rectangle(output, (startX, startY), (endX, endY),\n",
    "\t\t(0, 0, 255), 2)\n",
    "\tcv2.putText(output, text, (startX, startY - 20),\n",
    "\t\tcv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)\n",
    "\n",
    "\t# show the output image\n",
    "\tcv2.imshow(\"Text Detection\", output)\n",
    "\tcv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tesseract --help-psm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pytesseract import image_to_string\n",
    "\n",
    "\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import tensorflow \n",
    "\n",
    "# from tensorflow import keras\n",
    "# from keras.layers import Dense\n",
    "\n",
    "# from keras.models import load_model\n",
    "# import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_patch = \"images/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_string(img_path):\n",
    "    img = cv2.imread(img_path)  # Lendo imagem com OpenCV\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convertendo pra cinza\n",
    "\n",
    "    # Aplicando dilatação e erosão  para remover alguns ruidos\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    img = cv2.erode(img, kernel, iterations=1)\n",
    "    img = cv2.dilate(img, kernel, iterations=1)\n",
    "    \n",
    "    # img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "    # img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # img = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "    # img = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)\n",
    "    \n",
    "    img = cv2.Sobel(img,cv2.CV_8U,1,0,ksize=5)\n",
    "    \n",
    "\n",
    "    cv2.imwrite(\"removed_noise.png\", img)  # Sobreescrevendo a imagem depois de remover ruido\n",
    "\n",
    "    #  Apply threshold to get image with only black and white\n",
    "    #img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "\n",
    "    cv2.imwrite(\"thres.png\", img)  # Escrevendo a imagem depois de ser processada pelo OpenCV, para fazer algo..\n",
    "\n",
    "    result = pytesseract.image_to_string(Image.open(\"thres.png\"))  # Reconhecendo texto com Teeserract\n",
    "\n",
    "    # Remove template file\n",
    "    #os.remove(temp)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-- Iniciando recohecimento de Imagem --')\n",
    "print(get_string(\"pt.jpg\"))\n",
    "print('------ Feito ------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_string(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    img = cv2.erode(img, kernel, iterations=1)\n",
    "    \n",
    "    #dst = cv2.cornerHarris(kernel,3,3,0.00001)\n",
    "    img = cv2.Canny(img, threshold1=200, threshold2=300)\n",
    "    img = cv2.GaussianBlur(img, (3,3), 0 )\n",
    "\n",
    "    \n",
    "    cv2.imwrite(\"removed_noise.png\", img)\n",
    "    cv2.imwrite(\"thres.png\", img)\n",
    "    result = pytesseract.image_to_string(Image.open(\"thres.png\"))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-- Iniciando recohecimento de Imagem --')\n",
    "print(get_string(\"land03.png\"))\n",
    "print('------ Feito ------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(url):\n",
    "    global model      \n",
    "    # Read image\n",
    "    image = io.imread(url)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    image = cv2.resize(image, (500, 500), interpolation=cv2.INTER_CUBIC)    \n",
    "\n",
    "    # Use otsu to mask\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    mask = cv2.medianBlur(mask, 5)\n",
    "\n",
    "    img = mask\n",
    "    \n",
    "    '''\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    img = cv2.erode(img, kernel, iterations=1)\n",
    "    \n",
    "    #dst = cv2.cornerHarris(kernel,3,3,0.00001)\n",
    "    img = cv2.Canny(img, threshold1=200, threshold2=300)\n",
    "    img = cv2.GaussianBlur(img, (3,3), 0 )\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    cv2.imwrite(\"removed_noise.png\", img)\n",
    "    cv2.imwrite(\"thres.png\", img)\n",
    "    result = pytesseract.image_to_string(Image.open(\"thres.png\"))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-- Iniciando recohecimento de Imagem --')\n",
    "print(predict(\"land03.png\"))\n",
    "print('------ Feito ------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# contors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pytesseract import image_to_string\n",
    "\n",
    "import imutils\n",
    "from imutils import contours\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(img_path):\n",
    "    \n",
    "    img = io.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.threshold(img, 10, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "    \n",
    "    refCnts = cv2.findContours(img.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    refCnts = imutils.grab_contours(refCnts)\n",
    "    refCnts = contours.sort_contours(refCnts, method=\"left-to-right\")[0]\n",
    "    \n",
    "    img = imutils.resize(img, width=300)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "\n",
    "    tophat = cv2.morphologyEx(gray, cv2.MORPH_TOPHAT, kernel)\n",
    "\n",
    "\n",
    "    cv2.imwrite(\"removed_noise.png\", img)\n",
    "    cv2.imwrite(\"thres.png\", img)\n",
    "    result = pytesseract.image_to_string(Image.open(\"thres.png\"))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-- Iniciando recohecimento de Imagem --')\n",
    "print(test(\"panelaaco.png\"))\n",
    "print('------ Feito ------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('number.jpg')\n",
    "\n",
    "# get grayscale image\n",
    "def get_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# noise removal\n",
    "def remove_noise(image):\n",
    "    return cv2.medianBlur(image,5)\n",
    " \n",
    "#thresholding\n",
    "def thresholding(image):\n",
    "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "#dilation\n",
    "def dilate(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations = 1)\n",
    "    \n",
    "#erosion\n",
    "def erode(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations = 1)\n",
    "\n",
    "#opening - erosion followed by dilation\n",
    "def opening(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "#canny edge detection\n",
    "def canny(image):\n",
    "    return cv2.Canny(image, 100, 200)\n",
    "\n",
    "#skew correction\n",
    "def deskew(image):\n",
    "    coords = np.column_stack(np.where(image > 0))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "#template matching\n",
    "def match_template(image, template):\n",
    "    return cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('land03.png')\n",
    "\n",
    "gray = get_grayscale(image)\n",
    "thresh = thresholding(gray)\n",
    "opening = opening(gray)\n",
    "canny = canny(gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "im = cv2.imread('land03.jpg')\n",
    "a=[[5,2],[4,3]]\n",
    "c=np.asarray(im,dtype=float)\n",
    "im3 = c.copy()\n",
    "\n",
    "gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "thresh = cv2.adaptiveThreshold(blur,255,1,1,11,2)\n",
    "\n",
    "#################      Now finding Contours         ###################\n",
    "\n",
    "contours,hierarchy = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "samples =  np.empty((0,100))\n",
    "responses = []\n",
    "keys = [i for i in range(48,58)]\n",
    "\n",
    "for cnt in contours:\n",
    "    if cv2.contourArea(cnt)>50:\n",
    "        [x,y,w,h] = cv2.boundingRect(cnt)\n",
    "\n",
    "        if  h>28:\n",
    "            cv2.rectangle(im,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "            roi = thresh[y:y+h,x:x+w]\n",
    "            roismall = cv2.resize(roi,(10,10))\n",
    "            cv2.imshow('norm',im)\n",
    "            key = cv2.waitKey(0)\n",
    "\n",
    "            if key == 27:  # (escape to quit)\n",
    "                sys.exit()\n",
    "            elif key in keys:\n",
    "                responses.append(int(chr(key)))\n",
    "                sample = roismall.reshape((1,100))\n",
    "                samples = np.append(samples,sample,0)\n",
    "\n",
    "responses = np.array(responses,np.float32)\n",
    "responses = responses.reshape((responses.size,1))\n",
    "print(\"training complete\")\n",
    "\n",
    "np.savetxt('generalsamples.data',samples)\n",
    "np.savetxt('generalresponses.data',responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract as ocr\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "imagem = Image.open('panela.jpg').convert('RGB')\n",
    "\n",
    "npimagem = np.asarray(imagem).astype(np.uint8)  \n",
    "\n",
    "# diminuição dos ruidos antes da binarização\n",
    "npimagem[:, :, 2] = 0 # zerando o canal R (RED)\n",
    "npimagem[:, :, 0] = 0 # zerando o canal B (BLUE)\n",
    "\n",
    "im = cv2.cvtColor(npimagem, cv2.COLOR_RGB2GRAY) \n",
    "\n",
    "ret, thresh = cv2.threshold(im, 127, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU) \n",
    "\n",
    "binimagem = Image.fromarray(thresh) \n",
    "\n",
    "phrase = ocr.image_to_string(binimagem, lang='eng')\n",
    "\n",
    "print(phrase) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final(img_path):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    \n",
    "    npimagem = np.asarray(img).astype(np.uint8)  \n",
    "    npimagem[:, :, 0] = 0 # zerando o canal R (RED)\n",
    "    npimagem[:, :, 2] = 0 # zerando o canal B (BLUE)\n",
    "\n",
    "    im = cv2.cvtColor(npimagem, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    ret, img = cv2.threshold(im, 255, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU) \n",
    "    #img = Image.fromarray(thresh) \n",
    "    #img = ocr.image_to_string(binimagem, lang='eng')\n",
    "    \n",
    "\n",
    "    cv2.imwrite(\"removed_noise.png\", img)\n",
    "    cv2.imwrite(\"thres.png\", img)\n",
    "    result = pytesseract.image_to_string(Image.open(\"thres.png\"))\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-- Iniciando recohecimento de Imagem --')\n",
    "print(final(\"land01.png\"))\n",
    "print('------ Feito ------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pytesseract\n",
    "import argparse\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import sys\n",
    "from skimage import io\n",
    "import imutils\n",
    "from imutils import contours\n",
    "import argparse\n",
    "import pyautogui\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(image):\n",
    "    return pytesseract.image_to_string(image)\n",
    "\n",
    "#answer2 = pyautogui.screenshot(\"land02 copy.png\",region=(1526, 1142, 800, 800))\n",
    "img = Image.open(\"land02 copy.png\")\n",
    "answer2 = get_text(img)\n",
    "\n",
    "answer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "img = Image.open(\"land03.png\")\n",
    "\n",
    "print(pytesseract.image_to_string(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread('land02 copy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = img.copy()\n",
    "r = r[:, :, 0]\n",
    "g = img.copy()\n",
    "g = g[:, :, 1]\n",
    "b = img.copy()\n",
    "b = b[:, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(b,cmap='Blues_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(r,cmap='Reds_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(g,cmap='Greens_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(img.flatten())\n",
    "plt.xlim([0,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(r.flatten(),color='red',bw=0.005)\n",
    "sns.kdeplot(g.flatten(),color='green',bw=0.005)\n",
    "sns.kdeplot(b.flatten(),color='blue',bw=0.005)\n",
    "plt.xlim([0,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[0 , -1,  0],\n",
    "                   [-1,  5, -1],\n",
    "                   [0 , -1,  0]])\n",
    "\n",
    "opencvSaida= cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "plt.imshow(opencvSaida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[-1, -1, -1],\n",
    "                   [-1,  8, -1],\n",
    "                   [-1, -1, -1]])\n",
    "\n",
    "opencvSaida = cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "plt.imshow(opencvSaida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[ 1,  1,  1],\n",
    "                   [ 0,  0,  0],\n",
    "                   [-1, -1, -1]])\n",
    "\n",
    "opencvSaida = cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "plt.imshow(opencvSaida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencvSaida = cv2.GaussianBlur(img,(21,21),0)\n",
    "\n",
    "plt.imshow(opencvSaida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencvSaida = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(opencvSaida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencvSaida = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.imshow(opencvSaida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((1, 1), np.uint8)\n",
    "tt = cv2.erode(img, kernel, iterations=1)\n",
    "tt = cv2.dilate(img, kernel, iterations=1)\n",
    "\n",
    "opencvSaida = cv2.filter2D(tt, -1, kernel)\n",
    "\n",
    "plt.imshow(opencvSaida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencvSaida = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "plt.imshow(opencvSaida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencvSaida = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "plt.imshow(opencvSaida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencvSaida = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "\n",
    "plt.imshow(opencvSaida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencvSaida = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)\n",
    "\n",
    "plt.imshow(opencvSaida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencvSaida = cv2.Sobel(img,cv2.CV_8U,1,0,ksize=5)\n",
    "\n",
    "plt.imshow(opencvSaida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencvSaida = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.imshow(opencvSaida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencvSaida = cv2.erode(img, kernel, iterations=1)\n",
    "\n",
    "plt.imshow(opencvSaida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencvSaida = cv2.cornerHarris( kernel,3,3,0.00001)\n",
    "\n",
    "plt.imshow(opencvSaida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencvSaida = cv2.Canny(img, threshold1=200, threshold2=300)\n",
    "\n",
    "plt.imshow(opencvSaida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencvSaida = cv2.GaussianBlur(img, (3,3), 0 )\n",
    "\n",
    "plt.imshow(opencvSaida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencvSaida = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "opencvSaida = cv2.resize(img, (500, 500), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "plt.imshow(opencvSaida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, opencvSaida = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "opencvSaida = cv2.medianBlur(opencvSaida, 5)\n",
    "\n",
    "plt.imshow(opencvSaida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencvSaida = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "opencvSaida = cv2.threshold(img, 10, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "plt.imshow(opencvSaida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencvSaida = cv2.findContours(img.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "opencvSaida = imutils.grab_contours(opencvSaida)\n",
    "opencvSaida = contours.sort_contours(opencvSaida, method=\"left-to-right\")[0]\n",
    "\n",
    "plt.imshow(opencvSaida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencvSaida = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.imshow(opencvSaida) # get_grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencvSaida = cv2.medianBlur(img,5)\n",
    "\n",
    "plt.imshow(opencvSaida) # remove_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencvSaida = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "plt.imshow(opencvSaida) # thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernkel_dilation = np.ones((5,5),np.uint8)\n",
    "opencvSaida = cv2.dilate(img, kernkel_dilation, iterations = 1)\n",
    "\n",
    "plt.imshow(opencvSaida) # thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_erosion = np.ones((5,5),np.uint8)\n",
    "opencvSaida = cv2.erode(img, kernel_erosion, iterations = 1)\n",
    "\n",
    "plt.imshow(opencvSaida) # erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_opening = np.ones((5,5),np.uint8)\n",
    "opencvSaida = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel_opening)\n",
    "\n",
    "plt.imshow(opencvSaida) # opening - erosion followed by dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opencvSaida = cv2.Canny(img, 100, 200)\n",
    "\n",
    "plt.imshow(opencvSaida) # canny edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = np.column_stack(np.where(img > 0))\n",
    "angle = cv2.minAreaRect(coords)[-1]\n",
    "if angle < -45:\n",
    "    angle = -(90 + angle)\n",
    "else:\n",
    "    angle = -angle\n",
    "(h, w) = image.shape[:2]\n",
    "center = (w // 2, h // 2)\n",
    "M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "opencvSaida = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "plt.imshow(opencvSaida) # skew correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = cv2.imread('land03.png',0)\n",
    "opencvSaida = cv2.matchTemplate(img, template, cv2.TM_CCOEFF_NORMED) \n",
    "\n",
    "plt.imshow(opencvSaida) # template matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "thresh = cv2.adaptiveThreshold(blur,255,1,1,11,2)\n",
    "contours,hierarchy = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "opencvSaida  \n",
    "\n",
    "plt.imshow(hierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "ret, thresh = cv2.threshold(template, 127, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU) \n",
    "opencvSaida\n",
    "\n",
    "plt.imshow(thresh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
