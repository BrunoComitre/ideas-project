{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Start Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# https://medium.com/@dehhmesquita/classificando-textos-com-redes-neurais-e-tensorflow-5063784a1b31\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = tf.constant([1, 3, 6])\n",
    "y = tf.constant([1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "op = tf.add(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "create graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    x = tf.constant([1, 3, 6])\n",
    "    y = tf.constant([1, 1, 1])\n",
    "    \n",
    "    op = tf.add(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#DEPRECATED Session - https://www.tensorflow.org/guide/migrate\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "# with tf.Session(graph=graph) as sess:\n",
    "with tf.Session(graph=graph) as sess:    \n",
    "    x = tf.constant([1, 3, 6])\n",
    "    y = tf.constant([1, 1, 1])\n",
    "    \n",
    "    op = tf.add(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "run result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "# with tf.Session(graph=graph) as sess:\n",
    "with tf.Session(graph=graph) as sess:    \n",
    "    x = tf.constant([1, 3, 6])\n",
    "    y = tf.constant([1, 1, 1])\n",
    "    \n",
    "    op = tf.add(x, y)\n",
    "    result = sess.run(fetches=op)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Machine Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "total_words = 20\n",
    "# Network Parameters\n",
    "n_hidden_1 = 10        # 1st layer number of features\n",
    "n_hidden_2 = 5         # 2nd layer number of features\n",
    "n_input = total_words  # Words in vocab\n",
    "n_classes = 3          # Categories: graphics, space and baseball\n",
    "\n",
    "def multilayer_perceptron(input_tensor, weights, biases):\n",
    "    layer_1_multiplication = tf.matmul(input_tensor, weights['h1'])\n",
    "    layer_1_addition = tf.add(layer_1_multiplication, biases['b1'])\n",
    "    layer_1_activation = tf.nn.relu(layer_1_addition)\n",
    "    \n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2_multiplication = tf.matmul(layer_1_activation, weights['h2'])\n",
    "    layer_2_addition = tf.add(layer_2_multiplication, biases['b2'])\n",
    "    layer_2_activation = tf.nn.relu(layer_2_addition)\n",
    "    \n",
    "    # Output layer with linear activation\n",
    "    out_layer_multiplication = tf.matmul(layer_2_activation, weights['out'])\n",
    "    out_layer_addition = out_layer_multiplication + biases['out']\n",
    "    \n",
    "    return out_layer_addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "valores de entrada: x\n",
    "weights: w\n",
    "bias: b\n",
    "saída da rede: z\n",
    "    \n",
    "saída esperada: expected\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_tensor = 10\n",
    "weights = 5\n",
    "biases = 2\n",
    "#saída da rede: z\n",
    "    \n",
    "#saída esperada: expected\n",
    "\n",
    "\n",
    "# Construct model\n",
    "prediction = multilayer_perceptron(input_tensor, weights, biases)\n",
    "# Define loss\n",
    "entropy_loss = tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=output_tensor)\n",
    "loss = tf.reduce_mean(entropy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "# Construct model\n",
    "prediction = multilayer_perceptron(input_tensor, weights, biases)\n",
    "\n",
    "# Define loss\n",
    "entropy_loss = tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=output_tensor)\n",
    "loss = tf.reduce_mean(entropy_loss)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "vocab = Counter()\n",
    "text = \"Hi from Brazil\"\n",
    "\n",
    "#Get all words\n",
    "for word in text.split(' '):\n",
    "    word_lowercase = word.lower()\n",
    "    vocab[word_lowercase]+=1\n",
    "        \n",
    "#Convert words to indexes\n",
    "def get_word_2_index(vocab):\n",
    "    word2index = {}\n",
    "    for i,word in enumerate(vocab):\n",
    "        word2index[word] = i\n",
    "        \n",
    "    return word2index\n",
    "\n",
    "#Now we have an index\n",
    "word2index = get_word_2_index(vocab)\n",
    "total_words = len(vocab)\n",
    "\n",
    "#This is how we create a numpy array (our matrix)\n",
    "matrix = np.zeros((total_words),dtype=float)\n",
    "\n",
    "#Now we fill the values\n",
    "for word in text.split():\n",
    "    matrix[word2index[word]] += 1\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "matrix = np.zeros((total_words),dtype=float)\n",
    "text = \"Hi\"\n",
    "for word in text.split():\n",
    "    matrix[word2index[word.lower()]] += 1\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "category = 0\n",
    "\n",
    "y = np.zeros((3),dtype=float)\n",
    "\n",
    "if category == 0:\n",
    "    y[0] = 1.\n",
    "elif category == 1:\n",
    "    y[1] = 1.\n",
    "else:\n",
    "     y[2] = 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install minst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mnist = tf.keras.datasets.mnist.load_data('mnist', one_hot=True)\n",
    "\n",
    "#mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True) # y labels are oh-encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = mnist.train.num_examples # 55,000\n",
    "n_validation = mnist.validation.num_examples # 5000\n",
    "n_test = mnist.test.num_examples # 10,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
