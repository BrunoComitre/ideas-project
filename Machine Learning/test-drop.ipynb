{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import json\n",
    "import ijson\n",
    "from json_encoder import json\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LENDO DOS DADOS \n",
    "\n",
    "data = pd.read_json(\"req.json\", encoding='utf-8') # LENDO DOS DADOS \n",
    "data.drop(['_id','_rev'], axis=1, inplace=True) # REMOVENDO COLUNAS DESCENESSÁRIAS 1\n",
    "data = pd.DataFrame([md for md in data['requisicoes']]) # DATAFRAME\n",
    "data.drop(['hash','url'], axis=1, inplace=True) # REMOÇÃO DE COLUNAS 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_parsed = pd.DataFrame([md for md in data['parsed']])                                                  #                           ##\n",
    "parsed_requisicao_body = pd.DataFrame([md for md in parsed_requisicao['body']])                           ##\n",
    "parsed_requisicao_header = pd.DataFrame([md for md in parsed_requisicao['header']])                      ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.DataFrame([md for md in data['raw']])                                                        #\n",
    "raw_requisicao_body = pd.DataFrame([md for md in raw_requisicao['body']])                                 ##\n",
    "raw_requisicao_header = pd.DataFrame([md for md in raw_requisicao['header']])                            ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"Hello Mr. Smith, how are you doing today? The weather is great, and city is awesome.\n",
    "The sky is pinkish-blue. You shouldn't eat cardboard\"\"\"\n",
    "tokenized_text=sent_tokenize(text)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_word=word_tokenize(text)\n",
    "print(tokenized_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist(tokenized_word)\n",
    "print(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist.most_common(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist.plot(30,cumulative=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sent=[]\n",
    "for w in tokenized_sent:\n",
    "    if w not in stop_words:\n",
    "        filtered_sent.append(w)\n",
    "print(\"Tokenized Sentence:\",tokenized_sent)\n",
    "print(\"Filterd Sentence:\",filtered_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "stemmed_words=[]\n",
    "for w in filtered_sent:\n",
    "    stemmed_words.append(ps.stem(w))\n",
    "\n",
    "print(\"Filtered Sentence:\",filtered_sent)\n",
    "print(\"Stemmed Sentence:\",stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stem = PorterStemmer()\n",
    "\n",
    "word = \"flying\"\n",
    "print(\"Lemmatized Word:\",lem.lemmatize(word,\"v\"))\n",
    "print(\"Stemmed Word:\",stem.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "#tokenizer to remove unwanted elements from out data like symbols and numbers\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "text_counts= cv.fit_transform(tipoMime_prs_req)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### teste manhã sobre paginas html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re, string, unicodedata\n",
    "import nltk\n",
    "import contractions\n",
    "import inflect\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample=\"\"\"\n",
    "\"YUI.add('ipf_metaTags', function(Y){\\n\\t\\n\\t//Creamos el espacio de nombres para nuestro modulo\\n    Y.namespace('IPF_MetaTags');\\n    \\n    Y.IPF_MetaTags.nameMetaTagsLiferay = ['description', 'keywords', 'robots'];\\n\\n\\tY.IPF_MetaTags.ipf_init_metaTags = function (){\\n\\t\\tY.IPF_Util.extedsFuncionalityIE8();\\n\\t\\t\\n\\t\\tvar buttonAdd = Y.one('.add');\\n\\t\\tbuttonAdd.on('click', Y.IPF_MetaTags.ipf_buttonAddMetaTag);\\n\\t\\t\\n\\t\\tY.IPF_MetaTags.ipf_generateFormMetaTags();\\n\\t};\\n\\t\\n\\tY.IPF_MetaTags.ipf_generateFormMetaTags = function(){\\n\\t\\tY.on('domready', function() {\\n\\t\\t\\tvar divMetaTags =  Y.one('#divCustomMetaTags .lfr-input-text');\\n\\t\\t\\tif(divMetaTags != null){\\n\\t\\t\\t\\t\\n\\t\\t\\t\\tY.one('#divContentMetaTags').removeClass('hiddenLayer');\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t// Generar el formulario con los meta tags salvados\\n\\t\\t\\t\\tvar  JSONMetaTags = divMetaTags.get('value');\\n\\t\\t\\t\\tif(JSONMetaTags !== ''){\\n\\t\\t\\t\\t\\tvar mapMetaTags = Y.JSON.parse(JSONMetaTags);\\n\\t\\t\\t\\t\\tfor (keyName in mapMetaTags){\\n\\t\\t\\t\\t\\t\\tif (mapMetaTags.hasOwnProperty(keyName)) {\\n\\t\\t\\t\\t\\t\\t\\tvar content = mapMetaTags[keyName];\\n\\t\\t\\t\\t\\t\\t\\tY.IPF_MetaTags.ipf_addMetaTag(keyName, content);\\n\\t\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t}\\n\\t\\t\\t}\\t\\n\\t\\t});\\n\\t};\\n\\t\\n\\tY.IPF_MetaTags.ipf_addMetaTag = function(name, content){\\n\\t\\tvar divMetaTag = Y.one('#divMetaTags');\\n\\t\\tvar numChlidren = divMetaTag.get(\\\"children\\\").size();\\n\\t\\t\\n\\t\\tif(numChlidren === 1){// Al aÃ±adir el primer meta tag mostramos la capa que contiene el nombre y el contenido.\\n\\t\\t\\tY.IPF_Commons.ipf_changeClassHTMLElement('#divMetaTags', 'showLayer', 'hiddenLayer');\\n\\t\\t}\\n\\t\\t\\n\\t\\tvar metaTagId = 'metaTag'+(numChlidren+1);\\n\\t\\tvar divItemMetaTag = \\n\\t\\t\\t\\t'<div class=\\\"metaTag\\\" id=\\\"'+metaTagId+'\\\">'+\\n\\t\\t\\t\\t\\t'<div class=\\\"divInput\\\"><input class=\\\"name inputItem aui-field-input aui-field-input-text\\\" type=\\\"text\\\"/></div>'+\\n\\t\\t\\t\\t\\t'<div class=\\\"divInput\\\"><input class=\\\"content inputItem aui-field-input aui-field-input-text\\\" type=\\\"text\\\"/></div>'+\\n\\t\\t\\t\\t\\t'<div class=\\\"divButton\\\">'+\\n\\t\\t\\t\\t\\t\\t'<button type=\\\"button\\\" class=\\\"remove aui-buttonitem-icon-only aui-toolbar-last\\\">'+\\n\\t\\t\\t\\t\\t\\t\\t'<span class=\\\"aui-icon aui-icon-minus\\\"></span>'+\\n\\t\\t\\t\\t\\t\\t'</button>'+ \\n\\t\\t\\t\\t\\t'</div>'+\\n\\t\\t\\t\\t'</div>';\\n\\t\\tdivMetaTag.append(divItemMetaTag);\\n\\t\\t\\n\\t\\tvar nodesInputItem = divMetaTag.all('.inputItem');\\n\\t\\tvar lastInputContent = nodesInputItem.item(nodesInputItem.get('children').length-2);\\n\\t\\t\\n\\t\\tvar inputName = Y.one('#'+metaTagId+' .name');\\n\\t\\tvar inputContent = Y.one('#'+metaTagId+' .content');\\n\\t\\tif(name != null){\\n\\t\\t\\tinputName.set('value', name);\\n\\t\\t\\tinputName.set('disabled', true);\\n\\t\\t\\tinputName.addClass('inputNameDisabled');\\n\\t\\t\\t\\n\\t\\t\\tinputContent.set('value', content);\\n\\t\\t}else{\\n\\t\\t\\tlastInputContent.focus();\\n\\t\\t}\\n\\t\\t\\n\\t\\tvar nodesButtonRemove = divMetaTag.all('.remove');\\n\\t\\tvar lastButtonRemove = nodesButtonRemove.item(nodesButtonRemove.get('children').length-1);\\n\\t\\tlastButtonRemove.on('click', Y.IPF_MetaTags.ipf_buttonRemoveMetaTag, null, metaTagId);\\n\\t\\t\\n\\t\\t//El campo \\\"name\\\" no puede ser vacio ni estar duplicado\\n\\t\\tinputName.on('blur', Y.IPF_MetaTags.ipf_validateAllMetaTags);\\n\\t\\tinputName.on('keyup', Y.IPF_MetaTags.ipf_validateAllMetaTags);\\n\\t\\t\\n\\t\\t//El campo \\\"content\\\" \\n\\t\\tinputContent.on('blur', Y.IPF_MetaTags.ipf_validateAllMetaTags);\\n\\t\\tinputContent.on('keyup', Y.IPF_MetaTags.ipf_validateAllMetaTags);\\n\\t};\\n\\t\\n\\tY.IPF_MetaTags.ipf_buttonAddMetaTag = function(event){\\n\\t\\tif(!Y.IPF_MetaTags.ipf_validateAllMetaTags()){\\n\\t\\t\\tY.IPF_MetaTags.ipf_addMetaTag();\\n\\t\\t}\\n\\t};\\n\\t\\n\\tY.IPF_MetaTags.ipf_buttonRemoveMetaTag = function(event, metaTagId){\\n\\t\\tY.one('#'+metaTagId).remove();\\n\\t\\t\\n\\t\\tvar divMetaTag = Y.one('#divMetaTags');\\n\\t\\tvar numChlidren = divMetaTag.get(\\\"children\\\").size();\\n\\t\\t\\n\\t\\tif(numChlidren === 1){// Al aÃ±adir el primer meta tag ocultamos la capa que contiene el nombre y el contenido.\\n\\t\\t\\tY.IPF_Commons.ipf_changeClassHTMLElement('#divMetaTags', 'hiddenLayer', 'showLayer');\\n\\t\\t}\\n\\t\\t\\n\\t\\tY.IPF_MetaTags.ipf_validateAllMetaTags(event);\\n\\t};\\n\\t\\n\\tY.IPF_MetaTags.ipf_validateAllMetaTags = function(event){\\n\\t\\tvar mapValueName = {};\\n\\t\\t\\n\\t\\tvar validate = false;\\n\\t\\tvar liferayMetaTag = false;\\n\\t\\tvar specialCharacter = false;\\n\\t\\t\\n\\t\\tvar arrayNodeInputName = Y.all('#divMetaTags .name')._nodes;\\n\\t\\tvar arrayNodeInputContent = Y.all('#divMetaTags .content')._nodes;\\n\\t\\tfor(var i = 0; i<arrayNodeInputName.length && !validate && !liferayMetaTag && !specialCharacter; i++){\\n\\t\\t\\tvar name = arrayNodeInputName[i].value.trim().toLowerCase();\\n\\t\\t\\tvar content = arrayNodeInputContent[i].value.trim().toLowerCase();\\n\\t\\t\\t\\n\\t\\t\\tif(name === ''){\\n\\t\\t\\t\\tvalidate = true;\\n\\t\\t\\t}\\n\\t\\t\\t\\n\\t\\t\\t//Comprueba que no se dupliquen los meta tags isertados  \\n\\t\\t\\tif(mapValueName[name]==null){\\n\\t\\t\\t\\tmapValueName[name] = true;\\n\\t\\t\\t}else{\\n\\t\\t\\t\\tvalidate = true;\\n\\t\\t\\t}\\n\\t\\t\\t\\n\\t\\t\\t//Comprueba que no se redefinan los meta tags de liferay\\n\\t\\t\\tliferayMetaTag = Y.IPF_Util.seacrhToArray(Y.IPF_MetaTags.nameMetaTagsLiferay, name);\\n\\t\\t\\t\\n\\t\\t\\tspecialCharacter = \\tY.IPF_MetaTags.ipf_validateSpecialCharacter(name) || \\n\\t\\t\\t\\t\\t\\t\\t\\tY.IPF_MetaTags.ipf_validateSpecialCharacter(content);\\n\\t\\t}\\n\\t\\t\\n\\t\\tY.IPF_MetaTags.ipf_showMessageError(validate, liferayMetaTag,  specialCharacter);\\n\\t\\t\\n\\t\\treturn validate || liferayMetaTag || specialCharacter;\\n\\t};\\n\\t\\n\\tY.IPF_MetaTags.ipf_validateSpecialCharacter = function(contentOrName){\\n\\t\\tvar specialCharacter = false;\\n\\t\\tif(contentOrName.indexOf('\\\"') !== -1 || contentOrName.indexOf(\\\"'\\\") !== -1){\\n\\t\\t\\tspecialCharacter = true;\\n\\t\\t}\\n\\t\\t\\n\\t\\treturn specialCharacter;\\n\\t};\\n\\t\\n\\tY.IPF_MetaTags.ipf_showMessageError = function(validate, liferayMetaTag,  specialCharacter) {\\n\\t\\tvar error = validate || liferayMetaTag || specialCharacter;\\n\\t\\t\\n\\t\\tif(error){// Si hay algÃºn error en el formulario\\n\\t\\t\\t// Desactivamos el botÃ³n salvar\\n\\t\\t\\tY.IPF_Commons.ipf_disabledHTMLElement('.form-navigator .aui-button-input-submit');\\n\\t\\t\\t\\n\\t\\t\\t// Desactivamos el botÃ³n que permite aÃ±adir nuevos meta tags\\n\\t\\t\\tY.IPF_Commons.ipf_disabledHTMLElement('.add');\\n\\t\\t}else{\\n\\t\\t\\t// Activamos el botÃ³n salvar\\n\\t\\t\\tY.IPF_Commons.ipf_enabledHTMLElement('.form-navigator .aui-button-input-submit');\\n\\t\\t\\t\\n\\t\\t\\t// Activamos el botÃ³n que permite aÃ±adir nuevos meta tags\\n\\t\\t\\tY.IPF_Commons.ipf_enabledHTMLElement('.add');\\n\\t\\t\\t\\n\\t\\t\\tY.IPF_MetaTags.ipf_metaTagsToJSON();\\n\\t\\t}\\n\\t\\t\\n\\t\\tif(validate){\\n\\t\\t\\tY.IPF_Commons.ipf_changeClassHTMLElement('#messageErrorMetaTags', 'showMessageError', 'hiddenMessageError');\\n\\t\\t}else{\\n\\t\\t\\tY.IPF_Commons.ipf_changeClassHTMLElement('#messageErrorMetaTags', 'hiddenMessageError', 'showMessageError');\\n\\t\\t}\\n\\t\\t\\n\\t\\tif(liferayMetaTag){\\n\\t\\t\\tY.IPF_Commons.ipf_changeClassHTMLElement('#messageErrorMetaTagsLiferay', 'showMessageError', 'hiddenMessageError');\\n\\t\\t}else{\\n\\t\\t\\tY.IPF_Commons.ipf_changeClassHTMLElement('#messageErrorMetaTagsLiferay', 'hiddenMessageError', 'showMessageError');\\n\\t\\t}\\n\\t\\t\\n\\t\\tif(specialCharacter){\\n\\t\\t\\tY.IPF_Commons.ipf_changeClassHTMLElement('#messageErrorMetaTagsSpecialCharacter', 'showMessageError', 'hiddenMessageError');\\n\\t\\t}else{\\n\\t\\t\\tY.IPF_Commons.ipf_changeClassHTMLElement('#messageErrorMetaTagsSpecialCharacter', 'hiddenMessageError', 'showMessageError');\\n\\t\\t}\\n\\t};\\n\\t\\n\\tY.IPF_MetaTags.ipf_metaTagsToJSON = function(){\\n\\t\\tvar mapMetaTags = {};\\n\\t\\tvar arrayNodeInputName = Y.all('#divMetaTags .name')._nodes;\\n\\t\\tvar arrayNodeInputContent = Y.all('#divMetaTags .content')._nodes;\\n\\t\\tfor(var i = 0; i<arrayNodeInputName.length; i++){\\n\\t\\t\\tvar valueName = arrayNodeInputName[i].value.trim().toLowerCase();\\n\\t\\t\\tvar valueContent = arrayNodeInputContent[i].value.trim().toLowerCase();\\n\\t\\t\\tmapMetaTags[valueName] = valueContent;\\n\\t\\t}\\n\\t\\t\\n\\t\\t//Convertir el mapa a JSON\\n\\t\\tvar mapMetaTagToJSON = Y.JSON.stringify(mapMetaTags);\\n\\t\\t\\n\\t\\tY.one('#divCustomMetaTags .lfr-input-text').set('value', mapMetaTagToJSON);\\n\\t};\\n\\t\\n\\tY.IPF_MetaTags.ipf_printMetaTags = function(jsonMetaTags) {\\n\\t\\tif(jsonMetaTags !== ''){\\n\\t\\t\\tvar mapMetaTags = Y.JSON.parse(jsonMetaTags);\\n\\t\\t\\tvar metaTagsHead = '';\\n\\t\\t\\tfor (keyName in mapMetaTags) {\\n\\t\\t\\t\\tif (mapMetaTags.hasOwnProperty(keyName)) {\\n\\t\\t\\t\\t\\tvar content = mapMetaTags[keyName];\\n\\t\\t\\t\\t\\tmetaTagsHead += '<meta name=\\\"' + keyName +'\\\" content=\\\"' + content + '\\\">';\\n\\t\\t\\t\\t}\\n\\t\\t\\t}\\n\\t\\t\\t\\n\\t\\t\\tY.one('head').append(metaTagsHead);\\n\\t\\t}\\n\\t};\\n\\t\\n},'0.0.1', { requires: ['node-base', 'json-parse', 'json-stringify', 'ipf_commons', 'ipf_util'] });\\n\\n\",\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    return text\n",
    "\n",
    "sample = denoise_text(sample)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def replace_contractions(text): # Replace contractions in string of text\n",
    "    return contractions.fix(text)\n",
    "\n",
    "sample = replace_contractions(sample)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "words = nltk.word_tokenize(sample)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def remove_non_ascii(words): # Remove não ASCII\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words): # Converte minusculo\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words): # Remove pontuação\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words): # Replace all interger occurrences with textual representation\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words): # Remove stopwords\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def stem_words(words): #Stem words\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words): # Lemma\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def normalize(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = replace_numbers(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words\n",
    "\n",
    "words = normalize(words)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def stem_and_lemmatize(words):\n",
    "    stems = stem_words(words)\n",
    "    lemmas = lemmatize_verbs(words)\n",
    "    return stems, lemmas\n",
    "\n",
    "stems, lemmas = stem_and_lemmatize(words)\n",
    "print('Stemmed:\\n', stems)\n",
    "print('\\nLemmatized:\\n', lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "cnt = Counter()\n",
    "for word in lemmas:\n",
    "    cnt[word] += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cnt.values()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
