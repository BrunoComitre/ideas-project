{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;</p>\n",
    "</p><h1 style=\"text-align: center;\"><strong>Criação de API</strong></h1>\n",
    "<h1 style=\"text-align: center;\"><strong>Para recebimento de dados comportamentais</strong></h1>\n",
    "<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitetura de Software ou API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estrutura do documento:**\n",
    "\n",
    "- Histórico de revisões\n",
    "- Introdução\n",
    "- Visão geral\n",
    "- Requisitos não-funcionais\n",
    "- Mecanismos arquiteturais\n",
    "- Fundamentação\n",
    "- Visão de casos de uso\n",
    "- Componentes\n",
    "- Implantação\n",
    "- Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Histórico de revisões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "|    DATA    |  VERSÃO  |        DESCRIÇÃO        |        AUTOR        |\n",
    "|------------|----------|-------------------------|---------------------|\n",
    "| 26/03/2019 |    1.0   |    Documento inicial    | Bruno Alves Comitre |\n",
    "| 27/03/2019 |    1.4   | Alteração no item 3,4,5 | Bruno Alves Comitre |\n",
    "| 28/03/2019 |    1.5   |   Criação do item 6,7   | Bruno Alves Comitre |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Nesta fase do documento, o responsável teve com intuito apresentar de forma clara a objetividade do trabalho a ser  futuramente criado e documentado. De forma sucinta, descrever do que se trata o documento e quais assuntos serão abordados no mesmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Visão geral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Tem como objetivo, demonstrar de forma sucinta, os principais elementos que compõe uma futura arquitetura do sistema.\n",
    "\n",
    "**`Nota:`** Parte ainda sem nenhuma discussão\n",
    "\n",
    "Possivel definição como referência inicial para qualquer entidade que tenha ou pretende entender o sistema tecnicamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Requisitos não-funcionais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "No futuro de desenvolvimento listar os requisitos não funcionais encontrados no sistema, tais como: portabilidade, usabilidade, desempenho entre outros que possam afetar o tempo de resposta para uma predição.\n",
    "\n",
    "\n",
    "**Exemplo:**\n",
    "\n",
    "**Desempenho**\n",
    "\n",
    "1. A pagina principal tem que ser carregada em no máximo 3 segundos com uma conexão mínima de 1GB.\n",
    "\n",
    "2. As páginas que recuperam informações de sistemas legados, devem responder em dois segundos a cada 10.000 (contextual) em uma conexão de 1GB.\n",
    "\n",
    "3. As páginas que recuperam informações de transações no banco de dados da própria aplicação, deve responder em um segundo a cada 500 registros (contextual), retornados em uma conexão de 1GB.\n",
    "\n",
    "4. O servidor deve suportar 10.000 conexões simultâneas sem perda de desempenho.\n",
    "\n",
    "**Interoperabilidade**\n",
    "\n",
    "1. Deve ser desenvolvido na plataforma \"plataforma\" com banco de dados NoSql(Não-Relacional).\n",
    "\n",
    "\n",
    "**`Nota:`** Criação do documento: Criação de API para recebimento dos dados comportamentais.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Mecanismos arquiteturais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Identificar todos os mecanismos de análise, mecanismo de design e mecanismo de implementação. O intuito desta etapa é verificar e garantir que todas as preocupações técnicas relativas à arquitetura do sistema tenham sido capturadas.\n",
    "\n",
    "**`Nota:`** Criação do documento: Criação de API para recebimento dos dados comportamentais.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Fundamentação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Futura fundamentação de todas as decisões importantes de design. \n",
    "\n",
    "Descrevendo anotaçãoes de alternativas significativas rejeitadas no projeto. Indicando hipóteses e restrições, resultados de análises e experiências significativas para a arquitetura.\n",
    "\n",
    "\n",
    "- **Sprint:** Criação de front-end com dados para analise comportamental\n",
    "- **Info:** Utilização de javascript browser para capturar X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Visão de casos de uso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Fase responsável por apresentar os casos de uso ou cenários escolhidos para a validação da arquitetura apresentada.\n",
    "\n",
    "- Casos de uso\n",
    "- Backlog\n",
    "- Requisitos de usuários\n",
    "- Entre outros\n",
    "\n",
    "Ou seja, itens relevantes para o funcionamento do sistema final, o intuito é exercitar e testar os principais aspectos de risco da arquitetura.\n",
    "\n",
    "\n",
    "**Exemplo:**\n",
    "\n",
    "|APPSAFE-PENSADOR|  VERSÃO  |                     DESCRIÇÃO                    |      AUTOR     |\n",
    "|----------------|----------|--------------------------------------------------|----------------|\n",
    "|  Caso de uso 1 |    1.0   | Descrever o motivo e os itens que serão testados | Nome da Pessoa |\n",
    "|  Caso de uso 2 |    2.4   | Descrever o motivo e os itens que serão testados | Nome da Pessoa |\n",
    "|  Caso de uso 3 |    6.8   | Descrever o motivo e os itens que serão testados | Nome da Pessoa |\n",
    "|       ...      |    ...   |                        ...                       |       ...      |   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Componentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Apresentação do diagrama de componentes. É recomendado como boas praticas de mercado o uso do modelo UML para criação do diagrama, que deve apresentar os possíveis componentes e suas dependências, detalhando as responsabilidades de cada componente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Implantação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Descrição das configurações de distribuição dos componentes de software na área física em que serão implantados.\n",
    "\n",
    "**`Nota:`** Não se se há a real necessidade deste tópico. Por enquanto mantive para uma futura análise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos concluir com essa primeira revisão, que o importante é criar um documento que descreve com clareza os principais aspectos envolvidos no escopo do sistema. Este que para implementação Machine Learning podemos utilizar de algoritmos probabilisticos, para prever a probabilidade de cada classe diferente com base em vários atributos, onde se encontra múltiplas classes.\n",
    "\n",
    "\n",
    "### Modelos:\n",
    "\n",
    "Uma primeira avaliação demonstra que há a possibilidade de utilização de 2 algoritmos para uma possível probabilidade de predição de resultados dado a probabilidade de preditor dada a classe.\n",
    "\n",
    ">**1. Naive Bayes**\n",
    ">\n",
    ">É uma técnica de classificação baseada no teorema de Bayes que assume a independência entre preditores. Em termos simples, um classificador em Naive Bayes assume que a presença de uma característica particular em uma classe não é relacionada com a presença de nenhuma outra característica.\n",
    ">\n",
    ">**Exemplo:** Vamos usar um exemplo. Abaixo eu tenho um conjunto de dados de treinamento de tempo e a variável target correspondente `Play`. Agora, precisamos classificar se os usuários vão jogar ou não com base na condição meteorológica.\n",
    ">\n",
    ">**Possíveis passos:**\n",
    ">\n",
    ">- Passo 1: Converter o conjunto de dados para a tabela de frequência.\n",
    ">\n",
    ">- Passo 2: Criar tabela de Probabilidade de encontrar as probabilidades como probabilidade Caso Feliz = 0,29 e probabilidade de acerto é 0,64.\n",
    ">\n",
    ">- Passo 3: Agora, use a equação Bayesiana Naive para calcular a probabilidade posterior para cada classe. A classe com maior probabilidade posterior é o resultado de previsão.\n",
    ">\n",
    ">\n",
    ">**2. Catboost**\n",
    ">\n",
    ">O CatBoost é um algoritmo que pode se integrar facilmente a estruturas de deep learning como o TensorFlow.\n",
    ">\n",
    ">A melhor parte do CatBoost é que ele não exige treinamento extensivo de dados como outros modelos Machine Learning, e pode funcionar em uma variedade de formatos de dados, não diminuindo o quão robusto pode ser.\n",
    ">\n",
    ">\n",
    ">**Observação:**\n",
    ">\n",
    ">Certifique-se de tratar os valores faltantes antes de prosseguir com a implementação.\n",
    ">\n",
    ">O Catboost pode lidar automaticamente com variáveis categóricas sem mostrar o erro de conversão de tipo, o que ajuda você a se concentrar em ajustar melhor seu modelo em vez de resolver erros triviais.\n",
    "\n",
    "\n",
    "### Descoberta de Conhecimento em Banco de Dados:\n",
    "\n",
    "Em pesquisas relacionadas para esse tipo específico de campo de estudo, a melhor técnica que pode ser aplicada para a criação da API será a Extração de conhecimento (também conhecido como processo KDD, do inglês Knowledge Discovery in Databases).\n",
    "\n",
    "\n",
    ">**Possíveis passos:**\n",
    ">\n",
    ">- Passo 1: Etapa de seleção dos dados, pois isso irá gerar a base de dados e teremos todo tipo de ruído eliminado, como por exemplo os outliers.\n",
    ">\n",
    ">- Passo 2: Pré-processamento da informação: Colocando os dados em escala,ou matemática.\n",
    ">\n",
    ">- Passo 3: Transformação do dado pré-processado em algo que os algoritmos como o Naive Beyes e o Catboost compreendam. Podendo ser aplicado o conhecimento separado ou juntos em uma métrica apenas. Etapa de criação do Modelo e encontro do padrão desejado.\n",
    ">\n",
    ">- Passo 4: Depois de todo agrupamento dos dados, ocorrerá a análise destes dados interpretados pelo modelo de aprendizado de máquina.\n",
    "\n",
    "Lembrando que esses passos terão de alguma forma serem feitos pois apesar de usar Banco de Dados NoSql, algoritmos não entendem padrões hierárquicos que estão armazenados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Nota:`** O código abaixo ainda está em criação e estudo em relação de tempo de resposta e futuros testes de aprendizado de máquina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Nota:`** Os códigos abaixo foram retirados as vizualizações das variaveis geradas por motivo de travamento da máquina. Se você estiver em um ambiente com maior capacidade computacional é só retirar o `# **Comentário**`, para vizualização dos dados.\n",
    "\n",
    "Exemplo:\n",
    "\n",
    "```\n",
    "dado_bruto = json_normalize(dados)\n",
    "#dado_bruto.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Teste 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Analisando JSON aninhado com Pandas**\n",
    "\n",
    "- Criar um dataframe com pandas nivelado a partir de um array aninhado\n",
    "- Achatar outros arrays ou descompactar um array profundamente aninhado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Imports e Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd # processamento dos dados\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import numpy as np  # algebra linear\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "import time\n",
    "import json\n",
    "import ijson\n",
    "import rampy as rp\n",
    "from tqdm import tqdm\n",
    "from json_encoder import json\n",
    "from pandas.io.json import json_normalize # pacote para achatar json em pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Lendo Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('requisicoes.json') as f:\n",
    "    dados = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Observando Dados Brutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dado_bruto = json_normalize(dados)\n",
    "#dado_bruto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(len(dados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%bash head requisicoes.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%bash grep -E '^ {2}\"' requisicoes.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%bash grep -E '^ {2,6}\"' requisicoes.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Observando Dados Requisições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dado_req = json_normalize(dados['req'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(len(dados['req']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Foi Feito:**\n",
    "\n",
    "1. passou o caminho de dados do objeto json `dados[req]`\n",
    "\n",
    "2. passou o caminho do registro dentro do objeto que queriamos analisar `requisicoes`\n",
    "\n",
    "3. passou os metadados principais que desejamos anexar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Normalizando dados JSON semi-estruturados em uma tabela simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hash_data = json_normalize(data=dados['req'], record_path='hash')\n",
    "hash_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "resultadoEsperado_data = json_normalize(data=dados['req'], record_path='resultadoEsperado')\n",
    "resultadoEsperado_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "url_data = json_normalize(data=dados['req'], record_path='url')\n",
    "url_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "parsed_data = json_normalize(data=dados['req'], record_path='parsed')\n",
    "parsed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_data = json_normalize(data=dados['req'], record_path='raw')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "testesRealizados_data = json_normalize(data=dados['req'], record_path='testesRealizados')\n",
    "testesRealizados_data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "id_data = json_normalize(data=dados['requisicoes'], record_path='id')\n",
    "id_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### List Comprehension e Tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "column_names = [dados[\"req\"] for col in dados]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for char in tqdm(column_names):\n",
    "    time.sleep(0.1)\n",
    "    print(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####### OBS: Ao executar o código abaixo ele demora uma média de 17:26 minutos\n",
    "####### E tem como resposta: 100000it [17:26, 95.42it/s]\n",
    "####### Também foi comentado para evitar travamento da máquina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pbar = tqdm(column_names)\n",
    "for i in range(10000):\n",
    "    time.sleep(0.1)\n",
    "    pbar.update(10)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Tentativa sem fazer aninhamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filename = \"req.json\"\n",
    "with open(filename, 'r') as f:\n",
    "    objects = ijson.items(f, 'req')\n",
    "    columns = list(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#columns[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Erros para verificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "good_columns = [\"hash\", \"resultadoEsperado\", \"testesRealizados\", \"id\"]\n",
    "requisicoes = []\n",
    "with open(filename, 'r') as f:\n",
    "    objects = ijson.items(f, 'req')\n",
    "    for row in objects:\n",
    "        selected_row = []\n",
    "        for item in good_columns:\n",
    "           selected_row.append(row[column_names.index(parsed)])\n",
    "        data.append(selected_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dados['req'].goupby('parsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "req = json_normalize(data=dados['requisicoes'], record_path=['parsed', 'resposta','body',\n",
    "                                                                      'header'])\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "resultado_esperado = json_normalize(data=dados['req'], record_path=['parsed','reader'])\n",
    "resultado_esperado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Foi Feito:**\n",
    "    \n",
    "Foi encontrado outros dentro desses que seriam e vão ser analizados aqui em baixo:\n",
    "\n",
    "1. parsed.requisicao.header  \n",
    "\n",
    "2. parsed.resposta.header\n",
    "\n",
    "\n",
    "Talvez:\n",
    "\n",
    "1. raw.requisicao.header\n",
    "\n",
    "2. raw.resposta.body\n",
    "\n",
    "3. raw.resposta.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#flatten concerts column here\n",
    "requisicao_data = json_normalize(data=dados['req'], record_path='parsed', \n",
    "                            meta=['id', 'orchestra','programID', 'url'])\n",
    "requisicao_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#flatten concerts column here\n",
    "resposta_data = json_normalize(data=dados['req'], record_path='parsed', \n",
    "                            meta=['id', 'raw.resposta.tipoMime', 'season'])\n",
    "resposta_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Tratando os dados de json como se fossem dados Python convencionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd # processamento dos dados\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import numpy as np  # algebra linear\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "import time\n",
    "import json\n",
    "import ijson\n",
    "import rampy as rp\n",
    "from tqdm import tqdm\n",
    "from json_encoder import json\n",
    "from pandas.io.json import json_normalize # pacote para achatar json em pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lendo os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_json(\"req.json\")\n",
    "raw_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pegando apenas as requisições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = raw_data['req']\n",
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados aninhados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tirando o aninhamento**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = pd.DataFrame([md for md in dataset])\n",
    "provider.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider[\"parsed\"].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider[\"raw\"].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PARSED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_parsed = pd.DataFrame([md for md in provider[\"parsed\"]])\n",
    "provider_parsed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### requisicao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_requisicao = pd.DataFrame([md for md in provider_parsed[\"requisicao\"]])\n",
    "parsed_requisicao.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requisicao_header = pd.DataFrame([md for md in parsed_requisicao[\"header\"]])\n",
    "requisicao_header.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_resposta = pd.DataFrame([md for md in provider_parsed[\"resposta\"]])\n",
    "parsed_resposta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resposta_header = pd.DataFrame([md for md in parsed_resposta[\"header\"]])\n",
    "resposta_header.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### RAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "provider_raw = pd.DataFrame([md for md in provider[\"raw\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Requisicao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_requisicao = pd.DataFrame([md for md in provider_raw[\"requisicao\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "requisicao_header = pd.DataFrame([md for md in raw_requisicao[\"header\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_resposta = pd.DataFrame([md for md in provider_raw[\"resposta\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resposta_body = pd.DataFrame([md for md in raw_resposta[\"body\"]])\n",
    "resposta_body.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resposta_header = pd.DataFrame([md for md in raw_resposta[\"header\"]])\n",
    "#resposta_header.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Identificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Agora meio que temos um dataframe das variáveis!\n",
    "\n",
    "Mas eu diria que sem algum tipo de chave esses dados não nos fazem muito bem. Por isso foi adicionado a id para definir como o índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "parsed_requisicao['id'] = provider.id\n",
    "parsed_requisicao.set_index('id', inplace=True)\n",
    "parsed_requisicao.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "parsed_resposta['id'] = provider.id\n",
    "parsed_resposta.set_index('id', inplace=True)\n",
    "parsed_resposta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_requisicao['id'] = provider.id\n",
    "raw_requisicao.set_index('id', inplace=True)\n",
    "raw_requisicao.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_resposta['id'] = provider.id\n",
    "raw_resposta.set_index('id', inplace=True)\n",
    "raw_resposta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_requisicao = json_normalize(data=provider['raw_requisicao'])\n",
    "norm_requisicao.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possivel implementação do algoritmo de Edsger Dijkstra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Teste da internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "https://dev.to/mxl/dijkstras-algorithm-in-python-algorithms-for-beginners-dkc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from collections import deque, namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# we'll use infinity as a default distance to nodes.\n",
    "inf = float('inf')\n",
    "Edge = namedtuple('Edge', 'start, end, cost')\n",
    "\n",
    "\n",
    "def make_edge(start, end, cost=1):\n",
    "  return Edge(start, end, cost)\n",
    "\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self, edges):\n",
    "        # let's check that the data is right\n",
    "        wrong_edges = [i for i in edges if len(i) not in [2, 3]]\n",
    "        if wrong_edges:\n",
    "            raise ValueError('Wrong edges data: {}'.format(wrong_edges))\n",
    "\n",
    "        self.edges = [make_edge(*edge) for edge in edges]\n",
    "\n",
    "    @property\n",
    "    def vertices(self):\n",
    "        return set(\n",
    "            sum(\n",
    "                ([edge.start, edge.end] for edge in self.edges), []\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def get_node_pairs(self, n1, n2, both_ends=True):\n",
    "        if both_ends:\n",
    "            node_pairs = [[n1, n2], [n2, n1]]\n",
    "        else:\n",
    "            node_pairs = [[n1, n2]]\n",
    "        return node_pairs\n",
    "\n",
    "    def remove_edge(self, n1, n2, both_ends=True):\n",
    "        node_pairs = self.get_node_pairs(n1, n2, both_ends)\n",
    "        edges = self.edges[:]\n",
    "        for edge in edges:\n",
    "            if [edge.start, edge.end] in node_pairs:\n",
    "                self.edges.remove(edge)\n",
    "\n",
    "    def add_edge(self, n1, n2, cost=1, both_ends=True):\n",
    "        node_pairs = self.get_node_pairs(n1, n2, both_ends)\n",
    "        for edge in self.edges:\n",
    "            if [edge.start, edge.end] in node_pairs:\n",
    "                return ValueError('Edge {} {} already exists'.format(n1, n2))\n",
    "\n",
    "        self.edges.append(Edge(start=n1, end=n2, cost=cost))\n",
    "        if both_ends:\n",
    "            self.edges.append(Edge(start=n2, end=n1, cost=cost))\n",
    "\n",
    "    @property\n",
    "    def neighbours(self):\n",
    "        neighbours = {vertex: set() for vertex in self.vertices}\n",
    "        for edge in self.edges:\n",
    "            neighbours[edge.start].add((edge.end, edge.cost))\n",
    "\n",
    "        return neighbours\n",
    "\n",
    "    def dijkstra(self, source, dest):\n",
    "        assert source in self.vertices, 'Such source node doesn\\'t exist'\n",
    "        distances = {vertex: inf for vertex in self.vertices}\n",
    "        previous_vertices = {\n",
    "            vertex: None for vertex in self.vertices\n",
    "        }\n",
    "        distances[source] = 0\n",
    "        vertices = self.vertices.copy()\n",
    "\n",
    "        while vertices:\n",
    "            current_vertex = min(\n",
    "                vertices, key=lambda vertex: distances[vertex])\n",
    "            vertices.remove(current_vertex)\n",
    "            if distances[current_vertex] == inf:\n",
    "                break\n",
    "            for neighbour, cost in self.neighbours[current_vertex]:\n",
    "                alternative_route = distances[current_vertex] + cost\n",
    "                if alternative_route < distances[neighbour]:\n",
    "                    distances[neighbour] = alternative_route\n",
    "                    previous_vertices[neighbour] = current_vertex\n",
    "\n",
    "        path, current_vertex = deque(), dest\n",
    "        while previous_vertices[current_vertex] is not None:\n",
    "            path.appendleft(current_vertex)\n",
    "            current_vertex = previous_vertices[current_vertex]\n",
    "        if path:\n",
    "            path.appendleft(current_vertex)\n",
    "        return path\n",
    "\n",
    "\n",
    "graph = Graph([\n",
    "    (\"a\", \"b\", 7),  (\"a\", \"c\", 9),  (\"a\", \"f\", 14), (\"b\", \"c\", 10),\n",
    "    (\"b\", \"d\", 15), (\"c\", \"d\", 11), (\"c\", \"f\", 2),  (\"d\", \"e\", 6),\n",
    "    (\"e\", \"f\", 9)])\n",
    "\n",
    "print(graph.dijkstra(\"a\", \"e\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Por grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_resposta.groupby(['tipoMime']).size().reset_index(name='Quantity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_requisicao.groupby(['tipoMime']).size().reset_index(name='Quantity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_requisicao.groupby(['tipoMime']).size().reset_index(name='Quantity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_resposta.groupby(['tipoMime']).size().reset_index(name='Quantity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.path import Path\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alterando valores Nan para valores 0:\n",
    "parsed_resposta.fillna(0, inplace = True)\n",
    "parsed_requisicao.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Densidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_par_req = pd.get_dummies(parsed_requisicao.tipoMime , prefix='tipoMime')\n",
    "feature_par_req.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_par_rsp = pd.get_dummies(parsed_resposta.tipoMime , prefix='tipoMime')\n",
    "feature_par_rsp.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_raw_rsp = pd.get_dummies(raw_resposta.tipoMime , prefix='tipoMime')\n",
    "#feature_raw_rsp.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_raw_req = pd.get_dummies(raw_requisicao.tipoMime , prefix='tipoMime')\n",
    "#feature_raw_req.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.kdeplot(feature_par_req.sum(), shade=True, color=\"r\")\n",
    "ax = sns.kdeplot(feature_par_rsp.sum(), shade=True, color=\"b\")\n",
    "ax = sns.kdeplot(feature_raw_req.sum(), shade=True, color=\"g\")\n",
    "ax = sns.kdeplot(feature_raw_rsp.sum(), shade=True, color=\"y\")\n",
    "plt.title('Vendo se existe algum padrão de densidade')\n",
    "plt.ylabel('Densidade')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = pd.get_dummies(dataset.Pclass , prefix='Pclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_requisicao.values_counts()\n",
    "parsed_resposta.values_counts()\n",
    "raw_requisicao.values_counts()\n",
    "raw_resposta.values_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_resposta[\"header\"] e resposta_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Djinstra é usado para o cálculo do caminho mais curto em distância entre nós com isso se conseguisse verificar se existe uma relação\n",
    "significativa entre duas variáveis, poderiamos analisar os dados com um teste estatístico correlacional. O teste de correlação de Pearson é o mais utilizado, requerendo, entretanto, que tenhamos coletado as duas medidas em escala sendo elas intervalar ou de razão. E não poderia ser relacionado uma varável em escala intervalar e outra em escala nominal ou categórica. Pois o teste de Person procura entender como uma variável se comporta em um cenário onde outra está variando, visando identificar se existe alguma relação entre a variabilidade de ambas\n",
    "\n",
    "Com isso a gente cai no Naive Beyes conforme pensado, mas devido as questões dos dados teriamos de utilizar Laplace que coincide com as ideia bayesianas.\n",
    "\n",
    "A teoria das probabilidades, permite obter o cálculo das ocorrências possíveis num experimento aleatório, percorrendo o resultado a cada vez que o resultado é lançado. Possui classificação de tipos aleatórios e não aleatórios. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bom além de valores NaN existem valores nulo\n",
    "\n",
    "\n",
    "OBS: Mapear não resultou em nada"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
